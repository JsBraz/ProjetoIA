{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "import cv2\n",
    "import math\n",
    "import pafy\n",
    "import random\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "import tensorflow as tf\n",
    "from moviepy.editor import *\n",
    "from collections import deque\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.utils import plot_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "seed_constant = 23\n",
    "np.random.seed(seed_constant)\n",
    "random.seed(seed_constant)\n",
    "tf.random.set_seed(seed_constant)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# Inicializa a figure (gráfico) onde vão ser mosrados \n",
    "plt.figure(figsize = (30, 30))\n",
    "\n",
    "# Get Names of all classes in UCF50\n",
    "all_classes_names = os.listdir('UCF50')\n",
    "\n",
    "# Generate a random sample of images each time the cell runs\n",
    "random_range = random.sample(range(len(all_classes_names)), 20)\n",
    "\n",
    "# Iterating through all the random samples\n",
    "for counter, random_index in enumerate(random_range, 1):\n",
    "\n",
    "    # Getting Class Name using Random Index\n",
    "    selected_class_Name = all_classes_names[random_index]\n",
    "\n",
    "    # Getting a list of all the video files present in a Class Directory\n",
    "    video_files_names_list = os.listdir(f'UCF50/{selected_class_Name}')\n",
    "\n",
    "    # Randomly selecting a video file\n",
    "    selected_video_file_name = random.choice(video_files_names_list)\n",
    "\n",
    "    # Reading the Video File Using the Video Capture\n",
    "    video_reader = cv2.VideoCapture(f'UCF50/{selected_class_Name}/{selected_video_file_name}')\n",
    "\n",
    "    # Reading The First Frame of the Video File\n",
    "    _, bgr_frame = video_reader.read()\n",
    "\n",
    "    # Closing the VideoCapture object and releasing all resources.\n",
    "    video_reader.release()\n",
    "\n",
    "    # Converting the BGR Frame to RGB Frame\n",
    "    rgb_frame = cv2.cvtColor(bgr_frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Adding The Class Name Text on top of the Video Frame.\n",
    "    cv2.putText(rgb_frame, selected_class_Name, (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 0), 2)\n",
    "\n",
    "    # Assigning the Frame to a specific position of a subplot\n",
    "    plt.subplot(5, 4, counter)\n",
    "    plt.imshow(rgb_frame)\n",
    "    plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "image_height, image_width = 64, 64\n",
    "max_images_per_class = 8000\n",
    "\n",
    "dataset_directory = \"UCF50\"\n",
    "classes_list = [\"WalkingWithDog\", \"TaiChi\", \"Swing\", \"HorseRace\"]\n",
    "\n",
    "model_output_size = len(classes_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def frames_extraction(video_path):\n",
    "    # Empty List declared to store video frames\n",
    "    frames_list = []\n",
    "\n",
    "    # Reading the Video File Using the VideoCapture\n",
    "    video_reader = cv2.VideoCapture(video_path)\n",
    "\n",
    "    # Iterating through Video Frames\n",
    "    while True:\n",
    "\n",
    "        # Reading a frame from the video file\n",
    "        success, frame = video_reader.read()\n",
    "\n",
    "        # If Video frame was not successfully read then break the loop\n",
    "        if not success:\n",
    "            break\n",
    "\n",
    "        # Resize the Frame to fixed Dimensions\n",
    "        resized_frame = cv2.resize(frame, (image_height, image_width))\n",
    "\n",
    "        # Normalize the resized frame by dividing it with 255 so that each pixel value then lies between 0 and 1\n",
    "        normalized_frame = resized_frame / 255\n",
    "\n",
    "        # Appending the normalized frame into the frames list\n",
    "        frames_list.append(normalized_frame)\n",
    "\n",
    "    # Closing the VideoCapture object and releasing all resources.\n",
    "    video_reader.release()\n",
    "\n",
    "    # returning the frames list\n",
    "    return frames_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def create_dataset():\n",
    "\n",
    "    # Declaring Empty Lists to store the features and labels values.\n",
    "    temp_features = []\n",
    "    features = []\n",
    "    labels = []\n",
    "\n",
    "    # Iterating through all the classes mentioned in the classes list\n",
    "    for class_index, class_name in enumerate(classes_list):\n",
    "        print(f'Extracting Data of Class: {class_name}')\n",
    "\n",
    "        # Getting the list of video files present in the specific class name directory\n",
    "        files_list = os.listdir(os.path.join(dataset_directory, class_name))\n",
    "\n",
    "        # Iterating through all the files present in the files list\n",
    "        for file_name in files_list:\n",
    "\n",
    "            # Construct the complete video path\n",
    "            video_file_path = os.path.join(dataset_directory, class_name, file_name)\n",
    "\n",
    "            # Calling the frame_extraction method for every video file path\n",
    "            frames = frames_extraction(video_file_path)\n",
    "\n",
    "            # Appending the frames to a temporary list.\n",
    "            temp_features.extend(frames)\n",
    "\n",
    "        # Adding randomly selected frames to the features list\n",
    "        features.extend(random.sample(temp_features, max_images_per_class))\n",
    "\n",
    "        # Adding Fixed number of labels to the labels list\n",
    "        labels.extend([class_index] * max_images_per_class)\n",
    "\n",
    "        # Emptying the temp_features list so it can be reused to store all frames of the next class.\n",
    "        temp_features.clear()\n",
    "\n",
    "    # Converting the features and labels lists to numpy arrays\n",
    "    features = np.asarray(features)\n",
    "    labels = np.array(labels)\n",
    "\n",
    "    return features, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "features, labels = create_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Using Keras's to_categorical method to convert labels into one-hot-encoded vectors\n",
    "one_hot_encoded_labels = to_categorical(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "features_train, features_test, labels_train, labels_test = train_test_split(features, one_hot_encoded_labels, test_size = 0.2, shuffle = True, random_state = seed_constant)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Let's create a function that will construct our model\n",
    "def create_model():\n",
    "\n",
    "    # We will use a Sequential model for model construction\n",
    "    model = Sequential()\n",
    "\n",
    "    # Defining The Model Architecture\n",
    "    model.add(Conv2D(filters = 64, kernel_size = (3, 3), activation = 'relu', input_shape = (image_height, image_width, 3)))\n",
    "    model.add(Conv2D(filters = 64, kernel_size = (3, 3), activation = 'relu'))\n",
    "\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "    model.add(GlobalAveragePooling2D())\n",
    "\n",
    "    model.add(Dense(256, activation = 'relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dense(model_output_size, activation = 'softmax'))\n",
    "\n",
    "    # Printing the models summary\n",
    "    model.summary()\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "# Calling the create_model method\n",
    "model = create_model()\n",
    "\n",
    "print(\"Model Created Successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plot_model(model, to_file = 'model_structure_plot.png', show_shapes = True, show_layer_names = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Adding the Early Stopping Callback to the model which will continuously monitor the validation loss metric for every epoch.\n",
    "# If the models validation loss does not decrease after 15 consecutive epochs, the training will be stopped and the weight which reported the lowest validation loss will be retored in the model.\n",
    "early_stopping_callback = EarlyStopping(monitor = 'val_loss', patience = 15, mode = 'min', restore_best_weights = True)\n",
    "\n",
    "# Adding loss, optimizer and metrics values to the model.\n",
    "model.compile(loss = 'categorical_crossentropy', optimizer = 'Adam', metrics = [\"accuracy\"])\n",
    "\n",
    "# Start Training\n",
    "model_training_history = model.fit(x = features_train, y = labels_train, epochs = 50, batch_size = 4 , shuffle = True, validation_split = 0.2, callbacks = [early_stopping_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model_evaluation_history = model.evaluate(features_test, labels_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Creating a useful name for our model, incase you're saving multiple models (OPTIONAL)\n",
    "date_time_format = '%Y_%m_%d__%H_%M_%S'\n",
    "current_date_time_dt = dt.datetime.now()\n",
    "current_date_time_string = dt.datetime.strftime(current_date_time_dt, date_time_format)\n",
    "model_evaluation_loss, model_evaluation_accuracy = model_evaluation_history\n",
    "model_name = f'Model___Date_Time_{current_date_time_string}___Loss_{model_evaluation_loss}___Accuracy_{model_evaluation_accuracy}.h5'\n",
    "\n",
    "# Saving your Model\n",
    "model.save(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def plot_metric(metric_name_1, metric_name_2, plot_name):\n",
    "  # Get Metric values using metric names as identifiers\n",
    "  metric_value_1 = model_training_history.history[metric_name_1]\n",
    "  metric_value_2 = model_training_history.history[metric_name_2]\n",
    "\n",
    "  # Constructing a range object which will be used as time\n",
    "  epochs = range(len(metric_value_1))\n",
    "\n",
    "  # Plotting the Graph\n",
    "  plt.plot(epochs, metric_value_1, 'blue', label = metric_name_1)\n",
    "  plt.plot(epochs, metric_value_2, 'red', label = metric_name_2)\n",
    "\n",
    "  # Adding title to the plot\n",
    "  plt.title(str(plot_name))\n",
    "\n",
    "  # Adding legend to the plot\n",
    "  plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plot_metric('loss', 'val_loss', 'Total Loss vs Total Validation Loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plot_metric('accuracy', 'val_accuracy', 'Total Accuracy vs Total Validation Accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# reshape data into time steps of sub-sequences\n",
    "\n",
    "n_steps, n_length = 64, 64\n",
    "n_features = features_train.shape[3]\n",
    "\n",
    "features_train_lstm = features_train.reshape((features_train.shape[0], n_steps, n_length, n_features))\n",
    "features_test_lstm = features_test.reshape((features_test.shape[0], n_steps, n_length, n_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# fit and evaluate a model\n",
    "\n",
    "def create_modelLSTM():\n",
    "\n",
    "    model_LSTM = Sequential()\n",
    "    model_LSTM.add(TimeDistributed(Conv1D(filters=64, kernel_size=3, activation='relu'), input_shape=(None,n_length,n_features)))\n",
    "    model_LSTM.add(TimeDistributed(Conv1D(filters=64, kernel_size=3, activation='relu')))\n",
    "    model_LSTM.add(TimeDistributed(Dropout(0.5)))\n",
    "    model_LSTM.add(TimeDistributed(MaxPooling1D(pool_size=2)))\n",
    "    model_LSTM.add(TimeDistributed(Flatten()))\n",
    "    model_LSTM.add(LSTM(100))\n",
    "    model_LSTM.add(Dropout(0.5))\n",
    "    model_LSTM.add(Dense(64, activation='relu'))\n",
    "    model_LSTM.add(Dense(model_output_size, activation='softmax'))\n",
    "    model_LSTM.summary()\n",
    "    return model_LSTM\n",
    "\n",
    "model_LSTM = create_modelLSTM()\n",
    "print(\"Model Created Successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plot_model(model_LSTM, to_file = 'model_structure_plot.png', show_shapes = True, show_layer_names = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "early_stopping_callback_cnnlstm = EarlyStopping(monitor = 'val_loss', patience = 15, mode = 'min', restore_best_weights = True)\n",
    "\n",
    "model_LSTM.compile(loss = 'categorical_crossentropy', optimizer = 'Adam', metrics = [\"accuracy\"])\n",
    "\n",
    "epochs = 50\n",
    "batch_size = 4\n",
    "\n",
    "model_training_history_LSTM = model_LSTM.fit(x = features_train_lstm, y = labels_train, epochs = epochs, batch_size = batch_size , shuffle = True, validation_split = 0.2, callbacks = [early_stopping_callback_cnnlstm])\n",
    "\n",
    "model_LSTM.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model_evaluation_history = model_LSTM.evaluate(features_train_lstm, labels_test)\n",
    "\n",
    "# Creating a useful name for our model, incase you're saving multiple models (OPTIONAL)\n",
    "date_time_format = '%Y_%m_%d__%H_%M_%S'\n",
    "current_date_time_dt = dt.datetime.now()\n",
    "current_date_time_string = dt.datetime.strftime(current_date_time_dt, date_time_format)\n",
    "model_evaluation_loss, model_evaluation_accuracy = model_evaluation_history\n",
    "model_name = f'ModelLSTM___Date_Time_{current_date_time_string}___Loss_{model_evaluation_loss}___Accuracy_{model_evaluation_accuracy}.h5'\n",
    "\n",
    "# Saving your Model\n",
    "model.save(model_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def plot_metric_LSTM(metric_name_1, metric_name_2, plot_name):\n",
    "  # Get Metric values using metric names as identifiers\n",
    "  metric_value_1 = model_training_history_LSTM.history[metric_name_1]\n",
    "  metric_value_2 = model_training_history_LSTM.history[metric_name_2]\n",
    "\n",
    "  # Constructing a range object which will be used as time\n",
    "  epochs = range(len(metric_value_1))\n",
    "\n",
    "  # Plotting the Graph\n",
    "  plt.plot(epochs, metric_value_1, 'blue', label = metric_name_1)\n",
    "  plt.plot(epochs, metric_value_2, 'red', label = metric_name_2)\n",
    "\n",
    "  # Adding title to the plot\n",
    "  plt.title(str(plot_name))\n",
    "\n",
    "  # Adding legend to the plot\n",
    "  plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plot_metric_LSTM('loss', 'val_loss', 'LSTM Total Loss vs Total Validation Loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plot_metric_LSTM('accuracy', 'val_accuracy', 'LSTM Total Accuracy vs Total Validation Accuracy')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def download_youtube_videos(youtube_video_url, output_directory):\n",
    "    # Creating a Video object which includes useful information regarding the youtube video.\n",
    "    video = pafy.new(youtube_video_url)\n",
    "\n",
    "    # Getting the best available quality object for the youtube video.\n",
    "    video_best = video.getbest()\n",
    "\n",
    "    # Constructing the Output File Path\n",
    "    output_file_path = f'{output_directory}/{video.title}.mp4'\n",
    "\n",
    "    # Downloading the youtube video at the best available quality.\n",
    "    video_best.download(filepath = output_file_path, quiet = True)\n",
    "\n",
    "    # Returning Video Title\n",
    "    return video.title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def predict_on_live_video(video_file_path, output_file_path, window_size):\n",
    "\n",
    "    # Initialize a Deque Object with a fixed size which will be used to implement moving/rolling average functionality.\n",
    "    predicted_labels_probabilities_deque = deque(maxlen = window_size)\n",
    "\n",
    "    # Reading the Video File using the VideoCapture Object\n",
    "    video_reader = cv2.VideoCapture(video_file_path)\n",
    "\n",
    "    # Getting the width and height of the video\n",
    "    original_video_width = int(video_reader.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    original_video_height = int(video_reader.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "    # Writing the Overlayed Video Files Using the VideoWriter Object\n",
    "    video_writer = cv2.VideoWriter(output_file_path, cv2.VideoWriter_fourcc('M', 'P', '4', 'V'), 24, (original_video_width, original_video_height))\n",
    "\n",
    "    while True:\n",
    "\n",
    "        # Reading The Frame\n",
    "        status, frame = video_reader.read()\n",
    "\n",
    "        if not status:\n",
    "            break\n",
    "\n",
    "        # Resize the Frame to fixed Dimensions\n",
    "        resized_frame = cv2.resize(frame, (image_height, image_width))\n",
    "\n",
    "        # Normalize the resized frame by dividing it with 255 so that each pixel value then lies between 0 and 1\n",
    "        normalized_frame = resized_frame / 255\n",
    "\n",
    "        # Passing the Image Normalized Frame to the model and receiving Predicted Probabilities.\n",
    "        predicted_labels_probabilities = model_LSTM.predict(np.expand_dims(normalized_frame, axis = 0))[0]\n",
    "\n",
    "        # Appending predicted label probabilities to the deque object\n",
    "        predicted_labels_probabilities_deque.append(predicted_labels_probabilities)\n",
    "\n",
    "        # Assuring that the Deque is completely filled before starting the averaging process\n",
    "        if len(predicted_labels_probabilities_deque) == window_size:\n",
    "\n",
    "            # Converting Predicted Labels Probabilities Deque into Numpy array\n",
    "            predicted_labels_probabilities_np = np.array(predicted_labels_probabilities_deque)\n",
    "\n",
    "            # Calculating Average of Predicted Labels Probabilities Column Wise\n",
    "            predicted_labels_probabilities_averaged = predicted_labels_probabilities_np.mean(axis = 0)\n",
    "\n",
    "            # Converting the predicted probabilities into labels by returning the index of the maximum value.\n",
    "            predicted_label = np.argmax(predicted_labels_probabilities_averaged)\n",
    "\n",
    "            # Accessing The Class Name using predicted label.\n",
    "            predicted_class_name = classes_list[predicted_label]\n",
    "\n",
    "            # Overlaying Class Name Text Ontop of the Frame\n",
    "            cv2.putText(frame, predicted_class_name, (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 255), 2)\n",
    "\n",
    "        # Writing The Frame\n",
    "        video_writer.write(frame)\n",
    "\n",
    "\n",
    "        # cv2.imshow('Predicted Frames', frame)\n",
    "\n",
    "        # key_pressed = cv2.waitKey(10)\n",
    "\n",
    "        # if key_pressed == ord('q'):\n",
    "        #     break\n",
    "\n",
    "    # cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "    # Closing the VideoCapture and VideoWriter objects and releasing all resources held by them.\n",
    "    video_reader.release()\n",
    "    video_writer.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Creating The Output directories if it does not exist\n",
    "output_directory = 'Youtube_Videos'\n",
    "os.makedirs(output_directory, exist_ok = True)\n",
    "\n",
    "# Downloading a YouTube Video\n",
    "video_title = download_youtube_videos('https://www.youtube.com/watch?v=8u0qjmHIOcE', output_directory)\n",
    "\n",
    "# Getting the YouTube Video's path you just downloaded\n",
    "input_video_file_path = f'{output_directory}/{video_title}.mp4'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# Setting sthe Widow Size which will be used by the Rolling Averge Proces\n",
    "window_size = 1\n",
    "\n",
    "# Construting The Output YouTube Video Path\n",
    "output_video_file_path = f'{output_directory}/{video_title} -Output-WSize {window_size}.mp4'\n",
    "\n",
    "# Calling the predict_on_live_video method to start the Prediction.\n",
    "predict_on_live_video(input_video_file_path, output_video_file_path, window_size)\n",
    "\n",
    "# Play Video File in the Notebook\n",
    "VideoFileClip(output_video_file_path).ipython_display(width = 700)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Setting the Widow Size which will be used by the Rolling Averge Process\n",
    "window_size = 25\n",
    "\n",
    "# Construting The Output YouTube Video Path\n",
    "output_video_file_path = f'{output_directory}/{video_title} -Output-WSize {window_size}.mp4'\n",
    "\n",
    "# Calling the predict_on_live_video method to start the Prediction and Rolling Averge Process\n",
    "predict_on_live_video(input_video_file_path, output_video_file_path, window_size)\n",
    "\n",
    "# Play Video File in the Notebook\n",
    "VideoFileClip(output_video_file_path).ipython_display(width = 700)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def make_average_predictions(video_file_path, predictions_frames_count):\n",
    "\n",
    "    # Initializing the Numpy array which will store Prediction Probabilities\n",
    "    predicted_labels_probabilities_np = np.zeros((predictions_frames_count, model_output_size), dtype = np.float)\n",
    "\n",
    "    # Reading the Video File using the VideoCapture Object\n",
    "    video_reader = cv2.VideoCapture(video_file_path)\n",
    "\n",
    "    # Getting The Total Frames present in the video\n",
    "    video_frames_count = int(video_reader.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "\n",
    "    # Calculating The Number of Frames to skip Before reading a frame\n",
    "    skip_frames_window = video_frames_count // predictions_frames_count\n",
    "\n",
    "    for frame_counter in range(predictions_frames_count):\n",
    "\n",
    "        # Setting Frame Position\n",
    "        video_reader.set(cv2.CAP_PROP_POS_FRAMES, frame_counter * skip_frames_window)\n",
    "\n",
    "        # Reading The Frame\n",
    "        _ , frame = video_reader.read()\n",
    "\n",
    "        # Resize the Frame to fixed Dimensions\n",
    "        resized_frame = cv2.resize(frame, (image_height, image_width))\n",
    "\n",
    "        # Normalize the resized frame by dividing it with 255 so that each pixel value then lies between 0 and 1\n",
    "        normalized_frame = resized_frame / 255\n",
    "\n",
    "        # Passing the Image Normalized Frame to the model and receiving Predicted Probabilities.\n",
    "        predicted_labels_probabilities = model_LSTM.predict(np.expand_dims(normalized_frame, axis = 0))[0]\n",
    "\n",
    "        # Appending predicted label probabilities to the deque object\n",
    "        predicted_labels_probabilities_np[frame_counter] = predicted_labels_probabilities\n",
    "\n",
    "    # Calculating Average of Predicted Labels Probabilities Column Wise\n",
    "    predicted_labels_probabilities_averaged = predicted_labels_probabilities_np.mean(axis = 0)\n",
    "\n",
    "    # Sorting the Averaged Predicted Labels Probabilities\n",
    "    predicted_labels_probabilities_averaged_sorted_indexes = np.argsort(predicted_labels_probabilities_averaged)[::-1]\n",
    "\n",
    "    # Iterating Over All Averaged Predicted Label Probabilities\n",
    "    for predicted_label in predicted_labels_probabilities_averaged_sorted_indexes:\n",
    "\n",
    "        # Accessing The Class Name using predicted label.\n",
    "        predicted_class_name = classes_list[predicted_label]\n",
    "\n",
    "        # Accessing The Averaged Probability using predicted label.\n",
    "        predicted_probability = predicted_labels_probabilities_averaged[predicted_label]\n",
    "\n",
    "        print(f\"CLASS NAME: {predicted_class_name}   AVERAGED PROBABILITY: {(predicted_probability*100):.2}\")\n",
    "\n",
    "    # Closing the VideoCapture Object and releasing all resources held by it.\n",
    "    video_reader.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# Downloading The YouTube Video\n",
    "video_title = download_youtube_videos('https://www.youtube.com/watch?v=ceRjxW4MpOY', output_directory)\n",
    "\n",
    "# Construting The Input YouTube Video Path\n",
    "input_video_file_path = f'{output_directory}/{video_title}.mp4'\n",
    "\n",
    "# Calling The Make Average Method To Start The Process\n",
    "make_average_predictions(input_video_file_path, 50)\n",
    "\n",
    "# Play Video File in the Notebook\n",
    "VideoFileClip(input_video_file_path).ipython_display(width = 700)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Downloading The YouTube Video\n",
    "video_title = download_youtube_videos('https://www.youtube.com/watch?v=ayI-e3cJM-0', output_directory)\n",
    "\n",
    "# Construting The Input YouTube Video Path\n",
    "input_video_file_path = f'{output_directory}/{video_title}.mp4'\n",
    "\n",
    "# Calling The Make Average Method To Start The Process\n",
    "make_average_predictions(input_video_file_path, 50)\n",
    "\n",
    "# Play Video File in the Notebook\n",
    "VideoFileClip(input_video_file_path).ipython_display(width = 700)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Downloading The YouTube Video\n",
    "video_title = download_youtube_videos('https://www.youtube.com/watch?v=XqqpZS0c1K0', output_directory)\n",
    "\n",
    "# Construting The Input YouTube Video Path\n",
    "input_video_file_path = f'{output_directory}/{video_title}.mp4'\n",
    "\n",
    "# Calling The Make Average Method To Start The Process\n",
    "make_average_predictions(input_video_file_path, 50)\n",
    "\n",
    "# Play Video File in the Notebook\n",
    "VideoFileClip(input_video_file_path).ipython_display(width = 700)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Downloading The YouTube Video\n",
    "video_title = download_youtube_videos('https://www.youtube.com/watch?v=8u0qjmHIOcE', output_directory)\n",
    "\n",
    "# Construting The Input YouTube Video Path\n",
    "input_video_file_path = f'{output_directory}/{video_title}.mp4'\n",
    "\n",
    "# Calling The Make Average Method To Start The Process\n",
    "make_average_predictions(input_video_file_path, 50)\n",
    "\n",
    "# Play Video File in the Notebook\n",
    "VideoFileClip(input_video_file_path).ipython_display(width = 700)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}